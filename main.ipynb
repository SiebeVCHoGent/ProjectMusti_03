{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set numpy's random-state to 42 to make this notebook's output stable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload data** decides if a new dataframe has to be created. \\\n",
    "Default is False, but will be set to True if no dataframe exists yet.\\\n",
    "Can be set to True to force the program to overwrite an existing dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function 'target_value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_value(val):\n",
    "    if val == 'aanwezig':\n",
    "        return 2\n",
    "    if val == 'buiten':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if directory 'model' exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model/'):\n",
    "    os.mkdir('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a dataframe exists, and create a new one if this is not the case.\n",
    "Else load the existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataframe\n",
      "Saving DataFrame\n",
      "DataFrame Loaded\n",
      "     target  p1   p2  p3  p4  p5  p6  p7  p8  p9  ...  p225271  p225272  \\\n",
      "0         2  -1   -1  -1  -1  -1  -1  -1  -1  -1  ...     -125     -121   \n",
      "1         2  -1   -7  -1  -1  -1  -1  -1  -1  -1  ...      102      106   \n",
      "2         2  -1 -111  -1 -15  -1 -53  -1  -1  -1  ...      -24      -24   \n",
      "3         2  -1 -113  -1  -1  -1 -19  -1  -1  -1  ...       -1       -1   \n",
      "4         2  -1  126  -1  -4  -1  -1 -20  -1  -1  ...       -1       -1   \n",
      "..      ...  ..  ...  ..  ..  ..  ..  ..  ..  ..  ...      ...      ...   \n",
      "829       0  -1  -40  -1  -1  -1  -1 -26  -1  -1  ...     -106      -96   \n",
      "830       0  -1  -36  -1  -1  -1  -1 -44  -1  -1  ...      -44      -40   \n",
      "831       0  -1  110  -1 -23  -1 -71 -58  -1  -1  ...      -80      -62   \n",
      "832       0  -1  123  -1 -44  -1 -87 -23  -1  -1  ...      -31      -19   \n",
      "833       0  -1  -26  -1  -1  -1  -1  -1  -1  -1  ...       -1       -1   \n",
      "\n",
      "     p225273  p225274  p225275  p225276  p225277  p225278  p225279  p225280  \n",
      "0        127     -121     -105      -85      -77      -73      -73      -73  \n",
      "1       -121     -117     -113     -109     -101      -93      -89      -85  \n",
      "2         -3       -1       -1       -1       -1       -1       -1       -1  \n",
      "3         -1       -1       -1       -1       -1       -1       -1       -1  \n",
      "4         -1       -1       -1       -1       -1       -1       -1       -1  \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...  \n",
      "829     -110      -92      -68      -45      -21      -12      -12      -12  \n",
      "830      -15      -19       -7       -1       -1       -1       -1       -1  \n",
      "831      -27      -23      -18      -14       -1       -1       -1       -1  \n",
      "832       -1       -1       -1       -1       -1       -1       -1       -1  \n",
      "833       -1       -1       -1       -1       -1       -1       -1       -1  \n",
      "\n",
      "[834 rows x 225281 columns]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('./model/dataframe.sav'):\n",
    "    RELOAD_DATA = True # When there is not yet a dataframe, create one\n",
    "\n",
    "if RELOAD_DATA: # Check whether there needs to be created a new dataframe\n",
    "    #Extract when not already extracted\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        if not os.path.isfile('./data/classificatie.tar'):\n",
    "            raise Exception('Classificatie.tar not fount')\n",
    "\n",
    "        print('Extracting tar...')\n",
    "        tar = tarfile.open('./data/classificatie.tar')\n",
    "        tar.extractall('./data/')\n",
    "        tar.close()\n",
    "        print('Extracting tar Done!')\n",
    "\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        raise Exception('Extracted files not found')\n",
    "\n",
    "\n",
    "    # Get grayscale values from pictures\n",
    "    print('Creating dataframe')\n",
    "    samples = []\n",
    "    sample_counter = 0\n",
    "    musti = pd.DataFrame()\n",
    "\n",
    "    for folder in os.listdir('./data/classificatie/'):\n",
    "        for file in os.listdir(f'./data/classificatie/{folder}'):\n",
    "            img = cv2.imread(f'./data/classificatie/{folder}/{file}', 0)\n",
    "            img = cv2.normalize(img,np.zeros(img.shape), 0, 1000, cv2.NORM_MINMAX)\n",
    "\n",
    "            # add them to a dataframe\n",
    "            imgd = dict()\n",
    "            imgd['target'] = target_value(folder)\n",
    "            c = 0\n",
    "            for i in img.flatten():\n",
    "                c += 1\n",
    "                imgd[f'p{c}'] = i\n",
    "            samples.append(imgd)\n",
    "            sample_counter+=1\n",
    "            #print(file)\n",
    "\n",
    "            if sample_counter % 200==0:\n",
    "                temp_df = pd.DataFrame.from_dict(samples)\n",
    "                musti = musti.append(temp_df, ignore_index=True)\n",
    "                samples = []\n",
    "    temp_df = pd.DataFrame.from_dict(samples)\n",
    "    musti = musti.append(temp_df, ignore_index=True)\n",
    "    samples = []\n",
    "\n",
    "    print('Saving DataFrame')\n",
    "    \n",
    "    pickle.dump(musti, open('./model/dataframe.sav', 'wb'))\n",
    "else:\n",
    "    print('Loading DataFrame')\n",
    "    musti = pickle.load(open('./model/dataframe.sav', 'rb'))\n",
    "\n",
    "print('DataFrame Loaded')\n",
    "print(musti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4107142857142857 0\n",
      "0.5758354755784062 1\n",
      "0.0 2\n",
      "165 165 165\n"
     ]
    }
   ],
   "source": [
    "smallest_dataset_len = min(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))\n",
    "for i in range(3):\n",
    "    frac = 1 - smallest_dataset_len / len(musti[musti.target == i])\n",
    "    print(frac, i)\n",
    "    musti = musti.drop(musti.query(f'target == {i}').sample(frac=frac).index)\n",
    "\n",
    "print(len(musti[musti.target == 2]), len(musti[musti.target == 1]), len(musti[musti.target == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Shape: (396, 225280)\n"
     ]
    }
   ],
   "source": [
    "X, y = musti.drop('target', axis=1), musti['target']\n",
    "y = y.astype(np.uint8)  # less RAM space\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Training set Shape: {X_train.shape}')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model\n",
      "GridSearchCV(cv=3, estimator=RandomForestClassifier(),\n",
      "             param_grid=[{'max_features': [2, 4, 8],\n",
      "                          'n_estimators': [10, 100, 200],\n",
      "                          'random_state': [42]}],\n",
      "             verbose=2)\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "print('fitting model')\n",
    "\n",
    "#optimal params found with GridSearchCV for RandomForestClassifier\n",
    "param_grid = [\n",
    "    {'n_estimators': [135], \n",
    "     'max_features': [18],\n",
    "     'max_depth': [36],\n",
    "     'min_samples_split': [2],\n",
    "     'min_samples_leaf':[1],\n",
    "     'random_state': [42]},\n",
    "    ]\n",
    "\n",
    "gridsearch = GridSearchCV(model, param_grid, cv=3, verbose=2)\n",
    "print(gridsearch)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(gridsearch.best_params_,gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the chosen model and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cross_val_score(model, X_test, y_test, cv=3)\n",
    "print(f'\\t{a}')\n",
    "print(f'\\tmean: {np.mean(a)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5121bd3a35215f255f04af5486badf7493b805d644bc99080ec709e2d9bd47d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Python3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
