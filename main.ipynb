{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set numpy's random-state to 42 to make this notebook's output stable across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reload data** decides if a new dataframe has to be created. \\\n",
    "Default is False, but will be set to True if no dataframe exists yet.\\\n",
    "Can be set to True to force the program to overwrite an existing dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOAD_DATA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function 'target_value'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_value(val):\n",
    "    if val == 'aanwezig':\n",
    "        return 2\n",
    "    if val == 'buiten':\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if directory 'model' exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('./model/'):\n",
    "    os.mkdir('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if a dataframe exists, and create a new one if this is not the case.\n",
    "Else load the existing dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DataFrame\n",
      "DataFrame Loaded\n",
      "     target   p1   p2   p3   p4   p5   p6   p7   p8   p9  ...  p56311  p56312  \\\n",
      "0         2  107  116  116  110  110  106  110  111  109  ...      99      53   \n",
      "1         2  109  121  122  113  113  112  115  111  109  ...     -47    -125   \n",
      "2         2  107  119  120  111  113  109  110  112  107  ...     -50     126   \n",
      "3         2   90   96   97   89   90   90   92   98   89  ...     109      80   \n",
      "4         2   95   94   96   94   93   92   92   96   90  ...     111      84   \n",
      "..      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...     ...   \n",
      "812       0   46   45   42   49   41   40   44   44   45  ...      63      68   \n",
      "813       0   99  110  107  102  105  100  102  107  101  ...      59      65   \n",
      "814       0  111  120  120  114  111  112  115  114  106  ...      44      50   \n",
      "815       0   95  105  100   96   94   94   95  102   96  ...      76      82   \n",
      "816       0   70   75   75   76   76   78   80   82   75  ...      81      87   \n",
      "\n",
      "     p56313  p56314  p56315  p56316  p56317  p56318  p56319  p56320  \n",
      "0        37      35      36      38      38      46      51      50  \n",
      "1        97      95      97     103     113    -128    -109    -113  \n",
      "2        94      90      92     100     109     125    -119    -118  \n",
      "3        74      74      68      72      80      78     100     116  \n",
      "4        77      71      68      70      77      78      99     110  \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...  \n",
      "812      80      93     105     114     126    -100    -104    -111  \n",
      "813      74      87      93     110     119    -110    -112    -115  \n",
      "814      59      66      77      81      96     124     121     119  \n",
      "815      93     107     117     124    -123     -90     -95    -107  \n",
      "816     100     111     119     126    -116     -83     -87     -98  \n",
      "\n",
      "[817 rows x 56321 columns]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('./model/dataframe.sav'):\n",
    "    RELOAD_DATA = True # When there is not yet a dataframe, create one\n",
    "\n",
    "if RELOAD_DATA: # Check whether there needs to be created a new dataframe\n",
    "    #Extract when not already extracted\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        if not os.path.isfile('./data/classificatie.tar'):\n",
    "            raise Exception('Classificatie.tar not fount')\n",
    "\n",
    "        print('Extracting tar...')\n",
    "        tar = tarfile.open('./data/classificatie.tar')\n",
    "        tar.extractall('./data/')\n",
    "        tar.close()\n",
    "        print('Extracting tar Done!')\n",
    "\n",
    "    if not os.path.isdir('./data/classificatie'):\n",
    "        raise Exception('Extracted files not found')\n",
    "\n",
    "\n",
    "    # Get grayscale values from pictures\n",
    "    print('Creating dataframe')\n",
    "    samples = []\n",
    "    sample_counter = 0\n",
    "    musti = pd.DataFrame()\n",
    "\n",
    "    for folder in os.listdir('./data/classificatie/'):\n",
    "        for file in os.listdir(f'./data/classificatie/{folder}'):\n",
    "            if target_value(folder) == 1 or randint(1, 5) ==1:\n",
    "                img = cv2.imread(f'./data/classificatie/{folder}/{file}', 0)\n",
    "                img = cv2.resize(img, (320, 176))\n",
    "\n",
    "                # add them to a dataframe\n",
    "                imgd = dict()\n",
    "                imgd['target'] = target_value(folder)\n",
    "                c = 0\n",
    "                for i in img.flatten():\n",
    "                    c += 1\n",
    "                    imgd[f'p{c}'] = i\n",
    "                samples.append(imgd)\n",
    "                sample_counter+=1\n",
    "                #print(file)\n",
    "\n",
    "                if sample_counter % 200==0:\n",
    "                    temp_df = pd.DataFrame.from_dict(samples)\n",
    "                    musti = musti.append(temp_df, ignore_index=True)\n",
    "                    samples = []\n",
    "    temp_df = pd.DataFrame.from_dict(samples)\n",
    "    musti = musti.append(temp_df, ignore_index=True)\n",
    "    samples = []\n",
    "\n",
    "    print('Saving DataFrame')\n",
    "    \n",
    "    pickle.dump(musti, open('./model/dataframe.sav', 'wb'))\n",
    "else:\n",
    "    print('Loading DataFrame')\n",
    "    musti = pickle.load(open('./model/dataframe.sav', 'rb'))\n",
    "\n",
    "print('DataFrame Loaded')\n",
    "print(musti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set Shape: (653, 56320)\n"
     ]
    }
   ],
   "source": [
    "X, y = musti.drop('target', axis=1), musti['target']\n",
    "y = y.astype(np.uint8)  # less RAM space\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f'Training set Shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, random_state=42, min_samples_leaf=10)\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the chosen model and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = cross_val_score(model, X_test, y_test, cv=3)\n",
    "print(f'\\t{a}')\n",
    "print(f'\\tmean: {np.mean(a)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5121bd3a35215f255f04af5486badf7493b805d644bc99080ec709e2d9bd47d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Python3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
